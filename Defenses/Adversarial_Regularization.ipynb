{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Machine Learning with Membership Privacy using Adversarial Regularization\n",
    "## Milad Nasr, Reza Shokri, Amir Houmansadr\n",
    "https://arxiv.org/abs/1807.05852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import copy \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "sys.path.insert(0, '../Utils')\n",
    "\n",
    "import models\n",
    "from train import *\n",
    "from metrics import *  \n",
    "from data_downloaders import *\n",
    "\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"Pytorch: %s\" % torch.__version__)\n",
    "\n",
    "# determine device to run network on (runs on gpu if available)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "batch_size = 128\n",
    "lr_classification = 0.0001\n",
    "lr_inference = 0.001\n",
    "lr_attack = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define series of transforms to pre process images \n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Pad(2),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "n_classes = 10\n",
    "\n",
    "# load training set \n",
    "trainset = torchvision.datasets.CIFAR10('../Datasets/', train=True, transform=transform, download=True)\n",
    "testset = torchvision.datasets.CIFAR10('../Datasets/', train=False, transform=transform, download=True)\n",
    "\n",
    "total_size = len(trainset)\n",
    "split = int(total_size * 0.8)\n",
    "indices = list(range(total_size))\n",
    "\n",
    "D_idx = indices[:40000]\n",
    "D_A_idx = indices[:20000]\n",
    "D_prime_idx = indices[40000:45000]\n",
    "D_prime_A_idx = indices[45000:]\n",
    "\n",
    "eval_train = indices[20000:30000]\n",
    "#eval_out = #testset\n",
    "\n",
    "D_sampler = SubsetRandomSampler(D_idx)\n",
    "D_A_sampler = SubsetRandomSampler(D_A_idx)\n",
    "D_prime_sampler = SubsetRandomSampler(D_prime_idx)\n",
    "D_prime_A_sampler = SubsetRandomSampler(D_prime_A_idx)\n",
    "eval_train_sampler = SubsetRandomSampler(eval_train)\n",
    "\n",
    "\n",
    "D_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_sampler, num_workers=1)\n",
    "D_A_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_A_sampler, num_workers=1)\n",
    "D_prime_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_prime_sampler, num_workers=1)\n",
    "D_prime_A_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=D_prime_A_sampler, num_workers=1)\n",
    "eval_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=eval_train_sampler, num_workers=1)\n",
    "eval_out_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "# load test set \n",
    "#testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "# helper function to unnormalize and plot image \n",
    "def imshow(img):\n",
    "    img = np.array(img)\n",
    "    img = img / 2 + 0.5\n",
    "    img = np.moveaxis(img, 0, -1)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "# display sample from dataset \n",
    "imgs,labels = iter(D_loader).next()\n",
    "imshow(torchvision.utils.make_grid(imgs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inference_attack(nn.Module): \n",
    "    def __init__(self, n_classes): \n",
    "        super(inference_attack, self).__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.prediction_vector_block = nn.Sequential(\n",
    "            nn.Linear(n_classes, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 64), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.label_block = nn.Sequential(\n",
    "            nn.Linear(n_classes, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 64), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.common_block = nn.Sequential(\n",
    "            nn.Linear(128, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 1)  \n",
    "        )\n",
    "        \n",
    "    def forward(self, prediction_vector, one_hot_label): \n",
    "        prediction_block_out = self.prediction_vector_block(prediction_vector)\n",
    "        label_block_out = self.label_block(one_hot_label)\n",
    "        out = F.sigmoid(self.common_block(torch.cat((prediction_block_out, label_block_out), dim=1)))\n",
    "        return out\n",
    "    \n",
    "\n",
    "adversarial_regularization_net = inference_attack(n_classes).to(device)\n",
    "adversarial_regularization_net.apply(models.weights_init)\n",
    "\n",
    "adversarial_regularization_loss = nn.BCELoss()\n",
    "adversarial_regularization_optim = optim.Adam(adversarial_regularization_net.parameters(), lr=lr_inference)\n",
    "\n",
    "attack_net = inference_attack(n_classes).to(device)\n",
    "attack_net.apply(models.weights_init)\n",
    "\n",
    "attack_net2 = copy.deepcopy(attack_net)\n",
    "attack2_loss = nn.BCELoss()\n",
    "attack2_optim = optim.Adam(attack_net2.parameters(), lr=lr_attack)\n",
    "\n",
    "attack_loss = nn.BCELoss()\n",
    "attack_optim = optim.Adam(attack_net.parameters(), lr=lr_attack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Model (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torchvision.models.vgg16(num_classes=n_classes)\n",
    "# vgg16 fix for cifar10 image size \n",
    "vgg16.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64, n_classes),\n",
    "        )\n",
    "\n",
    "#net = resnet18.to(device)\n",
    "target_net = vgg16.to(device)\n",
    "target_net.apply(models.weights_init)\n",
    "target_loss = nn.CrossEntropyLoss()\n",
    "target_optim = optim.Adam(target_net.parameters(), lr=lr_classification)\n",
    "\n",
    "\n",
    "undefended_net = copy.deepcopy(target_net)\n",
    "undefended_loss = nn.CrossEntropyLoss()\n",
    "undefended_optim = optim.Adam(undefended_net.parameters(), lr=lr_classification)\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_onehot(labels, num_classes=10): \n",
    "    one_hot = torch.eye(num_classes)\n",
    "    return one_hot[labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_train(inference_net, classification_net, train_set, out_set, test_set, \n",
    "                      infer_optim, infer_loss, class_optim, class_loss, n_epochs, k, privacy_theta, verbose=False):\n",
    "    losses = []\n",
    "\n",
    "    inference_net.train()\n",
    "    classification_net.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        train_top = np.array([])\n",
    "        out_top = np.array([])\n",
    "        \n",
    "        train_p = np.array([])\n",
    "        out_p = np.array([])\n",
    "        \n",
    "        total_inference = 0\n",
    "        total_correct_inference = 0\n",
    "        \n",
    "        inference_losses = np.array([])\n",
    "        classification_losses = np.array([])\n",
    "        \n",
    "        for k_count in range(k): \n",
    "            # train inference network \n",
    "            train_imgs, train_lbls = iter(train_set).next()\n",
    "            train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "            out_imgs, out_lbls = iter(out_set).next()\n",
    "            out_imgs, out_lbls = out_imgs.to(device), out_lbls.to(device)\n",
    "            \n",
    "            mini_batch_size = train_imgs.shape[0]\n",
    "            \n",
    "            train_lbl = torch.ones(mini_batch_size).to(device)\n",
    "            out_lbl = torch.zeros(mini_batch_size).to(device)\n",
    "            \n",
    "            train_posteriors = F.softmax(classification_net(train_imgs), dim=1)\n",
    "            out_posteriors = F.softmax(classification_net(out_imgs), dim=1)\n",
    "            \n",
    "            '''\n",
    "            t_p = train_posteriors.cpu().detach().numpy().flatten()\n",
    "            o_p = out_posteriors.cpu().detach().numpy().flatten()\n",
    "            \n",
    "            train_p = np.concatenate((train_p, t_p))\n",
    "            out_p = np.concatenate((out_p, o_p))\n",
    "            '''\n",
    "            \n",
    "            train_sort, _ = torch.sort(train_posteriors, descending=True)\n",
    "            out_sort, _ = torch.sort(out_posteriors, descending=True)\n",
    "\n",
    "            t_p = train_sort[:,:4].cpu().detach().numpy().flatten()\n",
    "            o_p = out_sort[:,:4].cpu().detach().numpy().flatten()\n",
    "            \n",
    "            train_p = np.concatenate((train_p, t_p))\n",
    "            out_p = np.concatenate((out_p, o_p))\n",
    "                    \n",
    "            train_top = np.concatenate((train_top, train_sort[:,0].cpu().detach().numpy()))\n",
    "            out_top = np.concatenate((out_top, out_sort[:,0].cpu().detach().numpy()))\n",
    "            \n",
    "            infer_optim.zero_grad()\n",
    "\n",
    "            train_inference = torch.squeeze(inference_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "            out_inference = torch.squeeze(inference_net(out_posteriors, label_to_onehot(out_lbls).to(device)))\n",
    "            \n",
    "            total_inference += 2*mini_batch_size\n",
    "            total_correct_inference += torch.sum(train_inference > 0.5).item() + torch.sum(out_inference < 0.5).item()\n",
    "            \n",
    "            loss_train = infer_loss(train_inference, train_lbl)\n",
    "            loss_out = infer_loss(out_inference, out_lbl)\n",
    "            \n",
    "            loss = privacy_theta * (loss_train + loss_out) / 2 \n",
    "            loss.backward()\n",
    "            \n",
    "            infer_optim.step()\n",
    "            \n",
    "        # train classifiction network \n",
    "        train_imgs, train_lbls = iter(train_set).next()\n",
    "        train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "        \n",
    "        class_optim.zero_grad()\n",
    "\n",
    "        outputs = classification_net(train_imgs)\n",
    "        train_posteriors = F.softmax(outputs, dim=1)\n",
    "\n",
    "        loss_classification = class_loss(outputs, train_lbls)\n",
    "        train_lbl = torch.ones(mini_batch_size).to(device)\n",
    "        \n",
    "        train_inference = torch.squeeze(inference_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "        loss_infer = infer_loss(train_inference, train_lbl)\n",
    "        loss = loss_classification - privacy_theta * loss_infer\n",
    "        \n",
    "        loss.backward()\n",
    "        class_optim.step()\n",
    "        \n",
    "        '''\n",
    "        correct += (train_predictions>=0.5).sum().item()\n",
    "        correct += (out_predictions<0.5).sum().item()\n",
    "        total += train_predictions.size(0) + out_predictions.size(0)\n",
    "        print(\"[%d/%d][%d/%d] loss = %.2f, accuracy = %.2f\" % (epoch, n_epochs, i, len(shadow_train), loss.item(), 100 * correct / total))\n",
    "        '''        \n",
    "        \n",
    "        if epoch % 20 == 0 and epoch != 0 and verbose: \n",
    "\n",
    "            plt.figure()\n",
    "            sns.distplot(train_p,label='maximum train posterior')\n",
    "            sns.distplot(out_p,label='maximum out posterior')\n",
    "            #sns.distplot(train_top,label='maximum train posterior')\n",
    "            #sns.distplot(out_top,label='maximum out posterior')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            inference_accuracy = 100 * (total_correct_inference / total_inference)\n",
    "            classification_accuracy = eval_target_net(classification_net, test_set, classes=classes)\n",
    "            print(\"[%d/%d] Inference accuracy = %.2f%%, Classification accuracy = %.2f%%\" % (epoch, n_epochs, inference_accuracy, classification_accuracy))\n",
    "                  \n",
    "        \n",
    "def train_attacker(attack_net, target_net, attack_train, attack_out, optimizer, criterion, n_epochs, verbose=False):\n",
    "    losses = []\n",
    "\n",
    "    target_net.eval()\n",
    "    attack_net.train()\n",
    "    for epoch in range(n_epochs):\n",
    "       \n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        train_top = np.empty((0,2))\n",
    "        out_top = np.empty((0,2))\n",
    "        for i, ((train_imgs, train_lbls), (out_imgs, out_lbls)) in enumerate(zip(attack_train, attack_out)):\n",
    "\n",
    "            if train_imgs.shape[0] != out_imgs.shape[0]: \n",
    "                continue\n",
    "            mini_batch_size = train_imgs.shape[0]\n",
    "            train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "            out_imgs, out_lbls = out_imgs.to(device), out_lbls.to(device)\n",
    "\n",
    "            train_posteriors = F.softmax(target_net(train_imgs.detach()), dim=1)\n",
    "\n",
    "            out_posteriors = F.softmax(target_net(out_imgs.detach()), dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_sort, _ = torch.sort(train_posteriors, descending=True)\n",
    "            train_top_k = train_sort.clone().to(device)\n",
    "\n",
    "            out_sort, _ = torch.sort(out_posteriors, descending=True)\n",
    "            out_top_k = out_sort.clone().to(device)\n",
    "\n",
    "            train_top = np.vstack((train_top,train_top_k[:,:2].cpu().detach().numpy()))\n",
    "            out_top = np.vstack((out_top, out_top_k[:,:2].cpu().detach().numpy()))\n",
    "\n",
    "            train_lbl = torch.ones(mini_batch_size).to(device)\n",
    "            out_lbl = torch.zeros(mini_batch_size).to(device)\n",
    "            \n",
    "            train_inference = torch.squeeze(attack_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "            out_inference = torch.squeeze(attack_net(out_posteriors, label_to_onehot(out_lbls).to(device)))\n",
    "            \n",
    "            loss_train = criterion(train_inference, train_lbl)\n",
    "            loss_out = criterion(out_inference, out_lbl)\n",
    "            loss = (loss_train + loss_out) / 2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            correct += (train_inference>=0.5).sum().item()\n",
    "            correct += (out_inference<0.5).sum().item()\n",
    "            total += train_inference.size(0) + out_inference.size(0)\n",
    "\n",
    "            if verbose: \n",
    "                print(\"[%d/%d][%d/%d] loss = %.2f, accuracy = %.2f\" % (epoch, n_epochs, i, len(attack_train), loss.item(), 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_attacker(attack_net, target_net, attack_train, attack_out):\n",
    "\n",
    "    target_net.eval()\n",
    "    attack_net.eval()\n",
    "       \n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    for i, ((train_imgs, train_lbls), (out_imgs, out_lbls)) in enumerate(zip(attack_train, attack_out)):\n",
    "        mini_batch_size = train_imgs.shape[0]\n",
    "        train_imgs, train_lbls = train_imgs.to(device), train_lbls.to(device)\n",
    "        out_imgs, out_lbls = out_imgs.to(device), out_lbls.to(device)\n",
    "\n",
    "        train_posteriors = F.softmax(target_net(train_imgs.detach()), dim=1)\n",
    "        out_posteriors = F.softmax(target_net(out_imgs.detach()), dim=1)\n",
    "\n",
    "        train_inference = torch.squeeze(attack_net(train_posteriors, label_to_onehot(train_lbls).to(device)))\n",
    "        out_inference = torch.squeeze(attack_net(out_posteriors, label_to_onehot(out_lbls).to(device)))\n",
    "\n",
    "        true_positives += (train_inference >= 0.5).sum().item()\n",
    "        false_positives += (out_inference >= 0.5).sum().item()\n",
    "        false_negatives += (train_inference < 0.5).sum().item()\n",
    "        \n",
    "        correct += (train_inference>=0.5).sum().item()\n",
    "        correct += (out_inference<0.5).sum().item()\n",
    "        total += train_inference.size(0) + out_inference.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total \n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives != 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives !=0 else 0\n",
    "    print(\"accuracy = %.2f, precision = %.2f, recall = %.2f\" % (accuracy, precision, recall))\n",
    "    \n",
    "    return accuracy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with varying privacy lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tuples of (lambda, attack_accuracy, classification_train_accuracy, classification_test_accuracy)\n",
    "adv_reg_metrics = []\n",
    "\n",
    "\n",
    "for lambd in [0, 1, 2, 3, 10]: \n",
    "    adversarial_regularization_net = inference_attack(n_classes).to(device)\n",
    "    adversarial_regularization_net.apply(models.weights_init)\n",
    "\n",
    "    adversarial_regularization_loss = nn.BCELoss()\n",
    "    adversarial_regularization_optim = optim.Adam(adversarial_regularization_net.parameters(), lr=lr_inference)\n",
    "    \n",
    "    vgg16 = torchvision.models.vgg16(num_classes=n_classes)\n",
    "    # vgg16 fix for cifar10 image size \n",
    "    vgg16.classifier = nn.Sequential(\n",
    "                nn.Linear(512, 64),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(64, 64),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(64, n_classes),\n",
    "            )\n",
    "\n",
    "    #net = resnet18.to(device)\n",
    "    target_net = vgg16.to(device)\n",
    "    target_net.apply(models.weights_init)\n",
    "    target_loss = nn.CrossEntropyLoss()\n",
    "    target_optim = optim.Adam(target_net.parameters(), lr=lr_classification)\n",
    "    \n",
    "    adversarial_train(adversarial_regularization_net, target_net, D_loader, D_prime_loader, eval_out_loader,\n",
    "                  adversarial_regularization_optim, adversarial_regularization_loss, target_optim, \n",
    "                  target_loss, n_epochs, 7, lambd)\n",
    "    \n",
    "    attack_net = inference_attack(n_classes).to(device)\n",
    "    attack_net.apply(models.weights_init)\n",
    "\n",
    "    attack_loss = nn.BCELoss()\n",
    "    attack_optim = optim.Adam(attack_net.parameters(), lr=lr_attack)\n",
    "    \n",
    "    train_attacker(attack_net, target_net, D_A_loader, D_prime_A_loader, attack_optim, attack_loss, 20)\n",
    "    \n",
    "    print(\"\\nAttack performance on Adversarial Regularization Defense Network: \")\n",
    "    attack_accuracy = eval_attacker(attack_net, target_net, eval_train_loader, eval_out_loader)\n",
    "    \n",
    "    \n",
    "    print(\"\\nAdversarial Regularization network classification accuracy on training set: \")\n",
    "    train_accuracy = eval_target_net(target_net, D_loader, classes=None)\n",
    "\n",
    "    print(\"\\nAdversarial Regularization network classification accuracy on test set: \")\n",
    "    test_accuracy = eval_target_net(target_net, eval_out_loader, classes=None)\n",
    "\n",
    "    adv_reg_metrics.append((lambd,attack_accuracy, train_accuracy, test_accuracy))\n",
    "    \n",
    "    torch.save(target_net.state_dict(), './adv_reg_net_%d.pth' % lambd)\n",
    "    \n",
    "\n",
    "print(adv_reg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Regularization Results \n",
    "\n",
    "<!--\n",
    "[(0, 53.425, 73.9225, 66.35), (1, 52.945, 68.55499999999999, 62.73), (2, 51.545, 70.11749999999999, 64.3), (3, 52.485, 70.955, 65.07), (10, 51.395, 64.05999999999999, 59.86)]\n",
    "-->\n",
    "\n",
    "| $\\lambda$          |Train Accuracy | Test Accuracy | Attack Accuracy |\n",
    "| ------------------ |---------------| --------------|-----------------|\n",
    "| 0                  | 73.9 %        | 66.4 %        | 53.4 %          |\n",
    "| 1                  | 68.6 %        | 62.7 %        | 52.9 %          |\n",
    "| 2                  | 70.1 %        | 64.3 %        | 51.5 %          |\n",
    "| 3                  | 71 %          | 65 %          | 52.5 %          |\n",
    "| 10                 | 64.1 %        | 59.9 %        | 51.4 %          |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with L2 regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuples of (l2_factor, attack_accuracy, classification_train_accuracy, classification_test_accuracy)\n",
    "l2_reg_metrics = []\n",
    "\n",
    "\n",
    "for l2 in [0, 0.001, 0.005, 0.01]: \n",
    "    \n",
    "    vgg16 = torchvision.models.vgg16(num_classes=n_classes)\n",
    "    # vgg16 fix for cifar10 image size \n",
    "    vgg16.classifier = nn.Sequential(\n",
    "                nn.Linear(512, 64),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(64, 64),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(),\n",
    "                nn.Linear(64, n_classes),\n",
    "            )\n",
    "\n",
    "    target_net = vgg16.to(device)\n",
    "    target_net.apply(models.weights_init)\n",
    "    target_loss = nn.CrossEntropyLoss()\n",
    "    target_optim = optim.Adam(target_net.parameters(), lr=lr_classification, weight_decay=l2)\n",
    "    \n",
    "    \n",
    "    train(target_net, D_loader, eval_out_loader, target_optim, target_loss, \n",
    "          n_epochs=100, classes=None, verbose=False)\n",
    "    \n",
    "    attack_net = inference_attack(n_classes).to(device)\n",
    "    attack_net.apply(models.weights_init)\n",
    "\n",
    "    attack_loss = nn.BCELoss()\n",
    "    attack_optim = optim.Adam(attack_net.parameters(), lr=lr_attack)\n",
    "    \n",
    "    train_attacker(attack_net, target_net, D_A_loader, D_prime_A_loader, attack_optim, attack_loss, 20)\n",
    "    \n",
    "    print(\"\\nAttack performance on L2 regularized Network: \")\n",
    "    attack_accuracy = eval_attacker(attack_net, target_net, eval_train_loader, eval_out_loader)\n",
    "    \n",
    "    \n",
    "    print(\"\\nL2 regularized network classification accuracy on training set: \")\n",
    "    train_accuracy = eval_target_net(target_net, D_loader, classes=None)\n",
    "\n",
    "    print(\"\\nL2 regularized network classification accuracy on test set: \")\n",
    "    test_accuracy = eval_target_net(target_net, eval_out_loader, classes=None)\n",
    "\n",
    "    l2_reg_metrics.append((l2,attack_accuracy, train_accuracy, test_accuracy))\n",
    "    \n",
    "    torch.save(target_net.state_dict(), './l2_reg_net_%.3f.pth' % l2)\n",
    "print(l2_reg_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Results\n",
    "\n",
    "<!--\n",
    "[(0, 66.32, 99.6675, 74.82), (0.001, 63.85, 99.0425, 76.02), (0.005, 67.715, 95.965, 64.27000000000001), (0.01, 61.205, 77.6625, 60.19)]\n",
    "-->\n",
    "\n",
    "| L2-regularization  |Train Accuracy | Test Accuracy | Attack Accuracy |\n",
    "| ------------------ |---------------| --------------|-----------------|\n",
    "| 0                  | 99.6 %        | 74.8 %        | 66.3 %          |\n",
    "| 0.001              | 99 %          | 76 %          | 63.8 %          |\n",
    "| 0.005              | 95.9 %        | 64.2 %        | 67.7 %          |\n",
    "| 0.01               | 77.6 %        | 60.1 %        | 61.2 %          |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
